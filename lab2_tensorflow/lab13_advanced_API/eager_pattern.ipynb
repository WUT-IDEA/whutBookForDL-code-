{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF高级API - eager模式\n",
    "\n",
    "更多高级API参考\n",
    "https://github.com/GoogleCloudPlatform/tf-estimator-tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开启Eager模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "# set Eager API\n",
    "# use Eager model so that without tf.Session()\n",
    "tfe.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy与tensorflow相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'EagerTensor'> = tf.Tensor([[1. 1.]], shape=(1, 2), dtype=float64)\n",
      "<class 'numpy.ndarray'> = [[1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# numpy compatibility\n",
    "import numpy as np\n",
    "\n",
    "tf_tensor = tf.add(np.zeros(shape=(1, 2)), 1)\n",
    "print(type(tf_tensor), '=', tf_tensor)\n",
    "\n",
    "np_tensor = tf_tensor.numpy()\n",
    "print(type(np_tensor), '=', np_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager模式下用于检测，张良位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor is on [GPU:0]? False\n"
     ]
    }
   ],
   "source": [
    "with tf.device('CPU:0'):\n",
    "    tensor = tf.random_uniform(shape=(1, 2))\n",
    "    print('tensor is on [GPU:0]?', tensor.device.endswith('GPU:0'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager模式下，模型的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-383d6088b06e>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Episode 0 / 5, loss:0.83987, acc:0.78196\n",
      "Episode 1 / 5, loss:0.33577, acc:0.90691\n",
      "Episode 2 / 5, loss:0.27109, acc:0.92502\n",
      "Episode 3 / 5, loss:0.23340, acc:0.93587\n",
      "Episode 4 / 5, loss:0.20591, acc:0.94331\n",
      "Evaluation, loss:0.19729, acc:0.94330\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "class MNIST():\n",
    "    def __init__(self, batch_size=1000):\n",
    "        mnist = input_data.read_data_sets('../MNIST_data', one_hot=False)\n",
    "        self.dataset = {\n",
    "            'train': tf.data.Dataset.from_tensor_slices(\n",
    "                (mnist.train.images, mnist.train.labels)).batch(batch_size),\n",
    "            'test': tf.data.Dataset.from_tensor_slices(\n",
    "                (mnist.test.images, mnist.test.labels)).batch(batch_size)}\n",
    "        self.length = {'train': len(mnist.train.images) // batch_size,\n",
    "                       'test': len(mnist.test.images) // batch_size}\n",
    "        del mnist\n",
    "        self.dataset_iter = {key: self.init_dataset(value) for key, value in self.dataset.items()}\n",
    "\n",
    "    def init_dataset(self, dataset):\n",
    "        return tfe.Iterator(dataset)\n",
    "\n",
    "    def next(self, train=True):\n",
    "        tag = 'train' if train else 'test'\n",
    "        try:\n",
    "            batch_images, batch_labels = self.dataset_iter[tag].next()\n",
    "        except:\n",
    "            self.dataset_iter[tag] = self.init_dataset(self.dataset[tag])\n",
    "            batch_images, batch_labels = self.dataset_iter[tag].next()\n",
    "        batch_labels = tf.cast(batch_labels, dtype=tf.int64)\n",
    "        return batch_images, batch_labels\n",
    "\n",
    "    def __len__(self, train=True):\n",
    "        tag = 'train' if train else 'test'\n",
    "        return self.length[tag]\n",
    "\n",
    "\n",
    "class LinearNet(tfe.Network):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.layer1 = self.track_layer(tf.layers.Dense(128, activation=tf.nn.relu))\n",
    "        self.layer2 = self.track_layer(tf.layers.Dense(classes_num))\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "        self.grad = tfe.implicit_gradients(self.loss_fn)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "    def loss_fn(self, inputs, labels):\n",
    "        return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=self.call(inputs), labels=labels))\n",
    "\n",
    "    def accuracy_fn(self, inputs, labels):\n",
    "        predictions = tf.argmax(tf.nn.softmax(self.call(inputs)), axis=-1)\n",
    "        prob = tf.equal(labels, predictions)\n",
    "        return tf.reduce_mean(tf.cast(prob, dtype=tf.float32))\n",
    "\n",
    "    def optimize(self, inputs, labels):\n",
    "        gradients = self.grad(inputs, labels)\n",
    "        self.optimizer.apply_gradients(gradients)\n",
    "\n",
    "\n",
    "batch_size = 500\n",
    "mnist = MNIST()\n",
    "classes_num = 10\n",
    "linearNet = LinearNet()\n",
    "\n",
    "training_episode = 5\n",
    "for episode in xrange(training_episode):\n",
    "    loss, accuracy = 0.0, 0.0\n",
    "    for i in xrange(len(mnist)):\n",
    "        batch_images, batch_labels = mnist.next()\n",
    "        loss += linearNet.loss_fn(batch_images, batch_labels)\n",
    "        accuracy += linearNet.accuracy_fn(batch_images, batch_labels)\n",
    "        linearNet.optimize(batch_images, batch_labels)\n",
    "    loss /= len(mnist)\n",
    "    accuracy /= len(mnist)\n",
    "    print('Episode %s / %s, loss:%-.5f, acc:%-.5f' % (episode, training_episode, loss, accuracy))\n",
    "\n",
    "loss, accuracy = 0.0, 0.0\n",
    "for i in xrange(mnist.__len__(train=False)):\n",
    "    batch_images, batch_labels = mnist.next()\n",
    "    loss += linearNet.loss_fn(batch_images, batch_labels)\n",
    "    accuracy += linearNet.accuracy_fn(batch_images, batch_labels)\n",
    "    linearNet.optimize(batch_images, batch_labels)\n",
    "loss /= mnist.__len__(train=False)\n",
    "accuracy /= mnist.__len__(train=False)\n",
    "print('Evaluation, loss:%-.5f, acc:%-.5f' % (loss, accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
