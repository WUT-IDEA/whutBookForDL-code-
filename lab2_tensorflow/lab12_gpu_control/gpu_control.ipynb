{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 指定GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方式1：指定若干个GPU合并为一个GPU使用\n",
    "这种方式与多GPU加速不一样，不能加速模型训练，只是为了“扩张”环境的显存。<br>\n",
    "``\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1,2'\n",
    "``<br>\n",
    "或者在终端中运行<br>\n",
    "`CUDA_VISIBLE_DEVICES=2 python script.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方式2：指定网络在不同的GPU中\n",
    "该方式能够指定不同变量在不同的GPU中，同样地不能加速模型训练，只是为了“扩张”环境的显存。与方式一不同的是，该方式能够对每个变量指定GPU位置。<br>\n",
    "`tf.device('/GPU:1')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 显存控制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方式1：GPU 显存自动调用\n",
    "程序根据自身需要自动申请显存空间<br>\n",
    "``\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方式2：设置程序最大GPU 显存空间\n",
    "程序只能占据部分GPU显存空间<br>\n",
    "``\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "session = tf.Session(config=config)\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多GPU控制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该脚本在服务器上运行，终端无法执行ipynb文件。因此，只能讲结果写入注释(markdown)中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``\n",
    "服务器配置\n",
    "nvidia-smi\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 390.48                 Driver Version: 390.48                    |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
    "| 23%   36C    P8    16W / 250W |     25MiB / 11178MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
    "| 26%   44C    P8    18W / 250W |     25MiB / 11178MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   2  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
    "| 29%   48C    P8    20W / 250W |     25MiB / 11178MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   3  GeForce GTX 108...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
    "| 23%   33C    P8    17W / 250W |     25MiB / 11178MiB |      0%      Default |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                       GPU Memory |\n",
    "|  GPU       PID   Type   Process name                             Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+\n",
    "``\n",
    "<br>\n",
    "``\n",
    "nvidia-smi -L\n",
    "GPU 0: GeForce GTX 1080 Ti (UUID: GPU-0fb5007e-f81e-4154-0b90-4e9e3f0b76aa)\n",
    "GPU 1: GeForce GTX 1080 Ti (UUID: GPU-b188c27e-1cd2-e2a5-3272-bf5739833af6)\n",
    "GPU 2: GeForce GTX 1080 Ti (UUID: GPU-858b2a5a-db6c-de6e-8757-894aed84b2fd)\n",
    "GPU 3: GeForce GTX 1080 Ti (UUID: GPU-c2fb8f72-4fc0-bdca-c124-59071ed50bb4)\n",
    "``\n",
    "\n",
    "程序运行时\n",
    "![avatar](mgpu-nvidia-smi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多GPU训练原理图\n",
    "![avatar](mgpu.png)\n",
    "\n",
    "图片来源：https://github.com/normanheckscher/mnist-multi-gpu/blob/master/images/Parallelism.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_integer('batch_size', 100,\n",
    "                            \"\"\"Number of images to process in a batch.\"\"\")\n",
    "tf.app.flags.DEFINE_string('data_dir', './MNIST_data',\n",
    "                           \"\"\"Path to the MNIST data directory.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('num_epochs', 10,\n",
    "                            \"\"\"Number of epochs to run trainer.\"\"\")\n",
    "\n",
    "\n",
    "def _variable_on_cpu(name, shape):\n",
    "    with tf.device('/cpu:0'):\n",
    "        dtype = tf.float32\n",
    "        var = tf.get_variable(name, shape, dtype=dtype)\n",
    "    return var\n",
    "\n",
    "\n",
    "def inference1(images, reuse=False):\n",
    "    with tf.variable_scope('dense1', reuse=reuse):\n",
    "        dense1 = tf.layers.dense(images, units=512, activation=tf.nn.relu,\n",
    "                                 reuse=reuse)\n",
    "    with tf.variable_scope('dense2', reuse=reuse):\n",
    "        dense2 = tf.layers.dense(dense1, units=10, reuse=reuse)\n",
    "    return dense2\n",
    "\n",
    "\n",
    "def inference2(images):\n",
    "    with tf.variable_scope('dense1') as scope:\n",
    "        weight_w_1 = _variable_on_cpu(name='weight', shape=(784, 512))\n",
    "        weight_b_1 = _variable_on_cpu(name='biases', shape=(512,))\n",
    "        dense1 = tf.nn.relu(tf.matmul(images, weight_w_1) + weight_b_1, name=scope.name)\n",
    "    with tf.variable_scope('dense2') as scope:\n",
    "        weight_w_2 = _variable_on_cpu(name='weight', shape=(512, 10))\n",
    "        weight_b_2 = _variable_on_cpu(name='biases', shape=(10,))\n",
    "        dense2 = tf.nn.softmax(tf.matmul(dense1, weight_w_2) + weight_b_2, name=scope.name)\n",
    "    return dense2\n",
    "\n",
    "\n",
    "def loss(logits, labels):\n",
    "    \"\"\"Add L2Loss to all the trainable variables.\n",
    "\n",
    "    Add summary for \"Loss\" and \"Loss/avg\".\n",
    "    Args:\n",
    "      logits: Logits from inference().\n",
    "      labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
    "              of shape [batch_size]\n",
    "\n",
    "    Returns:\n",
    "      Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    # Calculate the average cross entropy loss across the batch.\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "    # The total loss is defined as the cross entropy loss plus all of the weight\n",
    "    # decay terms (L2 loss).\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads\n",
    "\n",
    "\n",
    "def check_available_gpus():\n",
    "    local_devices = device_lib.list_local_devices()\n",
    "    gpu_names = [x.name for x in local_devices if x.device_type == 'GPU']\n",
    "    gpu_list = len(gpu_names)\n",
    "    print('{0} GPUs are detected : {1}'.format(gpu_list, gpu_names))\n",
    "    gpu_list = ['/GPU:%s' % (i) for i in xrange(gpu_list)]\n",
    "    # gpu_list = ['/GPU:0', '/CPU:0']\n",
    "    return gpu_list\n",
    "\n",
    "\n",
    "def show_variables_info():\n",
    "    for var in tf.all_variables():\n",
    "        print((var.name, var.device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_gpus():\n",
    "    '''\n",
    "    build a new graph on the first GPU device, and other graphs reuse this graph\n",
    "     and they are built on other devices. These graphs' outputs(loss) will be processed\n",
    "     on the first device. (Faster than store graph on memory)\n",
    "    RECOMMEND!\n",
    "    '''\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.name_scope('placehold'):\n",
    "            x = tf.placeholder(dtype=tf.float32, shape=[None, 784], name='placehold_x')\n",
    "            y = tf.placeholder(dtype=tf.int64, shape=[None, ], name='placehold_y')\n",
    "        global_step = tf.get_variable(\n",
    "            'global_step', [],\n",
    "            initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "        gpu_list = check_available_gpus()\n",
    "        x_blocks = tf.split(x, num_or_size_splits=len(gpu_list))\n",
    "        y_blocks = tf.split(y, num_or_size_splits=len(gpu_list))\n",
    "\n",
    "        losses = []\n",
    "        logits = []\n",
    "        for ind, gpu_id in enumerate(gpu_list):\n",
    "            print('creating tensorflow variables on', gpu_id)\n",
    "            with tf.device(tf.DeviceSpec(device_type='GPU', device_index=ind)):\n",
    "                with tf.variable_scope(tf.get_variable_scope(), reuse=(ind > 0)):\n",
    "                    batch_logits = inference1(x_blocks[ind], reuse=(ind > 0))\n",
    "                    logits.append(batch_logits)\n",
    "                    batch_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                        logits=batch_logits,\n",
    "                        labels=y_blocks[ind])\n",
    "                    losses.append(batch_loss)\n",
    "        logits_op = tf.concat(logits, axis=0)\n",
    "        loss_op = tf.reduce_mean(tf.concat(losses, axis=0))\n",
    "        optimizer_op = tf.train.AdamOptimizer(1e-3) \\\n",
    "            .minimize(loss_op, global_step=global_step, colocate_gradients_with_ops=True)\n",
    "        accuracy_op = tf.reduce_mean(\n",
    "            tf.cast(tf.equal(tf.argmax(logits_op, axis=-1), y), dtype=tf.float32))\n",
    "\n",
    "        # Start running operations on the Graph.\n",
    "        config = tf.ConfigProto()\n",
    "        # 根据需要自动申请\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            show_variables_info()\n",
    "\n",
    "            mnist = input_data.read_data_sets(FLAGS.data_dir)\n",
    "            batch_size = FLAGS.batch_size * len(gpu_list)\n",
    "\n",
    "            print('gpus are:', gpu_list)\n",
    "            for step in xrange(FLAGS.num_epochs):\n",
    "                start = time.time()\n",
    "                for i in xrange(mnist.train.num_examples // batch_size):\n",
    "                    feed_dict = {x: mnist.train.images[i * batch_size:(i + 1) * batch_size],\n",
    "                                 y: mnist.train.labels[i * batch_size:(i + 1) * batch_size]}\n",
    "                    _ = sess.run([optimizer_op], feed_dict=feed_dict)\n",
    "                print('Episode %s / %s, training time cost: %-.5f' %\n",
    "                      (step + 1, FLAGS.num_epochs, time.time() - start))\n",
    "\n",
    "                loss_value, acc_value = 0.0, 0.0\n",
    "                for i in xrange(mnist.test.num_examples // batch_size):\n",
    "                    feed_dict = {x: mnist.test.images[i * batch_size:(i + 1) * batch_size],\n",
    "                                 y: mnist.test.labels[i * batch_size:(i + 1) * batch_size]}\n",
    "                    _, batch_loss, batch_acc = sess.run([optimizer_op, loss_op, accuracy_op], feed_dict=feed_dict)\n",
    "                    loss_value += batch_loss\n",
    "                    acc_value += batch_acc\n",
    "                loss_value /= mnist.test.num_examples // batch_size\n",
    "                acc_value /= mnist.test.num_examples // batch_size\n",
    "                print('Evaluate, loss: %-.5f, accuracy: %-.5f' % (loss_value, acc_value))\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``\n",
    "2018-07-17 21:31:58.625245: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
    "2018-07-17 21:31:58.922081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:02:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.74GiB\n",
    "2018-07-17 21:31:59.117733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:04:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.74GiB\n",
    "2018-07-17 21:31:59.315410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:83:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.74GiB\n",
    "2018-07-17 21:31:59.538070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:84:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.74GiB\n",
    "2018-07-17 21:31:59.542568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3\n",
    "2018-07-17 21:32:00.758096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2018-07-17 21:32:00.758161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3\n",
    "2018-07-17 21:32:00.758175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N N\n",
    "2018-07-17 21:32:00.758181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N N\n",
    "2018-07-17 21:32:00.758187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N Y\n",
    "2018-07-17 21:32:00.758193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   N N Y N\n",
    "2018-07-17 21:32:00.759096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 10390 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:32:00.858688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 10390 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:32:00.957837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:2 with 10390 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:32:01.057371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:3 with 10390 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:32:01.388051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3\n",
    "2018-07-17 21:32:01.388251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2018-07-17 21:32:01.388267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3\n",
    "2018-07-17 21:32:01.388276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N N\n",
    "2018-07-17 21:32:01.388283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N N\n",
    "2018-07-17 21:32:01.388289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N Y\n",
    "2018-07-17 21:32:01.388295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   N N Y N\n",
    "2018-07-17 21:32:01.388684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10390 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:32:01.388806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10390 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:32:01.388905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10390 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:32:01.389443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10390 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)\n",
    "WARNING:tensorflow:From multi_gpu_test.py:168: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
    "Instructions for updating:\n",
    "Please use tf.global_variables instead.\n",
    "WARNING:tensorflow:From multi_gpu_test.py:217: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
    "WARNING:tensorflow:From /home/duanwei/dw/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please write your own downloading logic.\n",
    "WARNING:tensorflow:From /home/duanwei/dw/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use tf.data to implement this functionality.\n",
    "WARNING:tensorflow:From /home/duanwei/dw/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use tf.data to implement this functionality.\n",
    "WARNING:tensorflow:From /home/duanwei/dw/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
    "4 GPUs are detected : ['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']\n",
    "creating tensorflow variables on /GPU:0\n",
    "creating tensorflow variables on /GPU:1\n",
    "creating tensorflow variables on /GPU:2\n",
    "creating tensorflow variables on /GPU:3\n",
    "('global_step:0', '')\n",
    "('dense1/dense/kernel:0', '/device:GPU:0')\n",
    "('dense1/dense/bias:0', '/device:GPU:0')\n",
    "('dense2/dense/kernel:0', '/device:GPU:0')\n",
    "('dense2/dense/bias:0', '/device:GPU:0')\n",
    "('beta1_power:0', '/device:GPU:0')\n",
    "('beta2_power:0', '/device:GPU:0')\n",
    "('dense1/dense/kernel/Adam:0', '/device:GPU:0')\n",
    "('dense1/dense/kernel/Adam_1:0', '/device:GPU:0')\n",
    "('dense1/dense/bias/Adam:0', '/device:GPU:0')\n",
    "('dense1/dense/bias/Adam_1:0', '/device:GPU:0')\n",
    "('dense2/dense/kernel/Adam:0', '/device:GPU:0')\n",
    "('dense2/dense/kernel/Adam_1:0', '/device:GPU:0')\n",
    "('dense2/dense/bias/Adam:0', '/device:GPU:0')\n",
    "('dense2/dense/bias/Adam_1:0', '/device:GPU:0')\n",
    "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
    "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
    "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "gpus are: ['/GPU:0', '/GPU:1', '/GPU:2', '/GPU:3']\n",
    "Episode 1 / 10, training time cost: 1.25556\n",
    "Evaluate, loss: 0.20625, accuracy: 0.93990\n",
    "Episode 2 / 10, training time cost: 0.49396\n",
    "Evaluate, loss: 0.12953, accuracy: 0.96330\n",
    "Episode 3 / 10, training time cost: 0.49255\n",
    "Evaluate, loss: 0.09254, accuracy: 0.97290\n",
    "Episode 4 / 10, training time cost: 0.50786\n",
    "Evaluate, loss: 0.07031, accuracy: 0.97900\n",
    "Episode 5 / 10, training time cost: 0.49639\n",
    "Evaluate, loss: 0.05516, accuracy: 0.98440\n",
    "Episode 6 / 10, training time cost: 0.49450\n",
    "Evaluate, loss: 0.04426, accuracy: 0.98860\n",
    "Episode 7 / 10, training time cost: 0.48309\n",
    "Evaluate, loss: 0.03612, accuracy: 0.99130\n",
    "Episode 8 / 10, training time cost: 0.49725\n",
    "Evaluate, loss: 0.02988, accuracy: 0.99290\n",
    "Episode 9 / 10, training time cost: 0.49990\n",
    "Evaluate, loss: 0.02475, accuracy: 0.99420\n",
    "Episode 10 / 10, training time cost: 0.49276\n",
    "Evaluate, loss: 0.02050, accuracy: 0.99500\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_cpus_and_gpus():\n",
    "    '''\n",
    "    build graph on memory firstly, compute on GPU device\n",
    "    '''\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.name_scope('placehold'):\n",
    "            x = tf.placeholder(dtype=tf.float32, shape=[None, 784], name='placehold_x')\n",
    "            y = tf.placeholder(dtype=tf.int64, shape=[None, ], name='placehold_y')\n",
    "        global_step = tf.get_variable(\n",
    "            'global_step', [],\n",
    "            initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "        gpu_list = check_available_gpus()\n",
    "        x_blocks = tf.split(x, num_or_size_splits=len(gpu_list))\n",
    "        y_blocks = tf.split(y, num_or_size_splits=len(gpu_list))\n",
    "\n",
    "        optimizer_op = tf.train.AdamOptimizer(1e-3)\n",
    "        gradients_list = []\n",
    "        logits = []\n",
    "        with tf.variable_scope(tf.get_variable_scope()):\n",
    "            for ind, gpu_id in enumerate(gpu_list):\n",
    "                print('creating tensorflow variables on', gpu_id)\n",
    "                with tf.device(gpu_id):\n",
    "                    batch_logits = inference2(x_blocks[ind])\n",
    "                    logits.append(batch_logits)\n",
    "                    _ = loss(batch_logits, y_blocks[ind])\n",
    "                    losses = tf.get_collection('losses')\n",
    "                    loss_op = tf.add_n(losses, name='total_loss')\n",
    "\n",
    "                    # Reuse variables for the next tower.\n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                    gradients = optimizer_op.compute_gradients(loss_op)\n",
    "                    gradients_list.append(gradients)\n",
    "        gradients = average_gradients(gradients_list)\n",
    "        train_op = optimizer_op.apply_gradients(gradients, global_step=global_step)\n",
    "        accuracy_op = tf.reduce_mean(tf.cast(tf.equal(\n",
    "            tf.argmax(tf.concat(logits, axis=0), axis=-1), y),\n",
    "            dtype=tf.float32))\n",
    "\n",
    "        # Start running operations on the Graph.\n",
    "        config = tf.ConfigProto()\n",
    "        # 根据需要自动申请\n",
    "        config.gpu_options.allow_growth = True\n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            show_variables_info()\n",
    "\n",
    "            mnist = input_data.read_data_sets(FLAGS.data_dir)\n",
    "            batch_size = FLAGS.batch_size * len(gpu_list)\n",
    "\n",
    "            print('gpus are:', gpu_list)\n",
    "            for step in xrange(FLAGS.num_epochs):\n",
    "                start = time.time()\n",
    "                for i in xrange(mnist.train.num_examples // batch_size):\n",
    "                    feed_dict = {x: mnist.train.images[i * batch_size:(i + 1) * batch_size],\n",
    "                                 y: mnist.train.labels[i * batch_size:(i + 1) * batch_size]}\n",
    "                    _ = sess.run([train_op], feed_dict=feed_dict)\n",
    "                print('Episode %s / %s, training time cost: %-.5f' %\n",
    "                      (step + 1, FLAGS.num_epochs, time.time() - start))\n",
    "\n",
    "                loss_value, acc_value = 0.0, 0.0\n",
    "                for i in xrange(mnist.test.num_examples // batch_size):\n",
    "                    feed_dict = {x: mnist.test.images[i * batch_size:(i + 1) * batch_size],\n",
    "                                 y: mnist.test.labels[i * batch_size:(i + 1) * batch_size]}\n",
    "                    _, batch_loss, batch_acc = sess.run([train_op, loss_op, accuracy_op], feed_dict=feed_dict)\n",
    "                    loss_value += batch_loss\n",
    "                    acc_value += batch_acc\n",
    "                loss_value /= mnist.test.num_examples // batch_size\n",
    "                acc_value /= mnist.test.num_examples // batch_size\n",
    "                print('Evaluate, loss: %-.5f, accuracy: %-.5f' % (loss_value, acc_value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``\n",
    "2018-07-17 21:25:38.061286: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
    "2018-07-17 21:25:38.368119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:02:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.74GiB\n",
    "2018-07-17 21:25:38.566151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:04:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.74GiB\n",
    "2018-07-17 21:25:38.793769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:83:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.74GiB\n",
    "2018-07-17 21:25:39.025796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties:\n",
    "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
    "pciBusID: 0000:84:00.0\n",
    "totalMemory: 10.92GiB freeMemory: 10.74GiB\n",
    "2018-07-17 21:25:39.030258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3\n",
    "2018-07-17 21:25:40.249204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2018-07-17 21:25:40.249267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3\n",
    "2018-07-17 21:25:40.249282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N N\n",
    "2018-07-17 21:25:40.249290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N N\n",
    "2018-07-17 21:25:40.249296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N Y\n",
    "2018-07-17 21:25:40.249303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   N N Y N\n",
    "2018-07-17 21:25:40.250104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 10390 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:25:40.350039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 10390 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:25:40.449366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:2 with 10390 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:25:40.550163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:3 with 10390 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:25:41.313835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3\n",
    "2018-07-17 21:25:41.314027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
    "2018-07-17 21:25:41.314042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3\n",
    "2018-07-17 21:25:41.314051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N N\n",
    "2018-07-17 21:25:41.314058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N N\n",
    "2018-07-17 21:25:41.314065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N Y\n",
    "2018-07-17 21:25:41.314071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   N N Y N\n",
    "2018-07-17 21:25:41.314438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10390 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:25:41.314570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10390 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:25:41.314677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10390 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\n",
    "2018-07-17 21:25:41.315636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10390 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:84:00.0, compute capability: 6.1)\n",
    "WARNING:tensorflow:From multi_gpu_test.py:168: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
    "Instructions for updating:\n",
    "Please use tf.global_variables instead.\n",
    "WARNING:tensorflow:From multi_gpu_test.py:290: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
    "WARNING:tensorflow:From /home/duanwei/dw/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please write your own downloading logic.\n",
    "WARNING:tensorflow:From /home/duanwei/dw/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use tf.data to implement this functionality.\n",
    "WARNING:tensorflow:From /home/duanwei/dw/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use tf.data to implement this functionality.\n",
    "WARNING:tensorflow:From /home/duanwei/dw/venv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "Instructions for updating:\n",
    "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
    "4 GPUs are detected : ['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']\n",
    "creating tensorflow variables on /GPU:0\n",
    "creating tensorflow variables on /GPU:1\n",
    "creating tensorflow variables on /GPU:2\n",
    "creating tensorflow variables on /GPU:3\n",
    "('global_step:0', '')\n",
    "('dense1/weight:0', '/device:CPU:0')\n",
    "('dense1/biases:0', '/device:CPU:0')\n",
    "('dense2/weight:0', '/device:CPU:0')\n",
    "('dense2/biases:0', '/device:CPU:0')\n",
    "('beta1_power:0', '/device:CPU:0')\n",
    "('beta2_power:0', '/device:CPU:0')\n",
    "('dense1/weight/Adam:0', '/device:CPU:0')\n",
    "('dense1/weight/Adam_1:0', '/device:CPU:0')\n",
    "('dense1/biases/Adam:0', '/device:CPU:0')\n",
    "('dense1/biases/Adam_1:0', '/device:CPU:0')\n",
    "('dense2/weight/Adam:0', '/device:CPU:0')\n",
    "('dense2/weight/Adam_1:0', '/device:CPU:0')\n",
    "('dense2/biases/Adam:0', '/device:CPU:0')\n",
    "('dense2/biases/Adam_1:0', '/device:CPU:0')\n",
    "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
    "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
    "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
    "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
    "gpus are: ['/GPU:0', '/GPU:1', '/GPU:2', '/GPU:3']\n",
    "Episode 1 / 10, training time cost: 1.56065\n",
    "Evaluate, loss: 6.19163, accuracy: 0.92630\n",
    "Episode 2 / 10, training time cost: 0.66851\n",
    "Evaluate, loss: 6.09537, accuracy: 0.94500\n",
    "Episode 3 / 10, training time cost: 0.64818\n",
    "Evaluate, loss: 6.04356, accuracy: 0.95770\n",
    "Episode 4 / 10, training time cost: 0.64884\n",
    "Evaluate, loss: 6.01031, accuracy: 0.96330\n",
    "Episode 5 / 10, training time cost: 0.65422\n",
    "Evaluate, loss: 5.98554, accuracy: 0.96980\n",
    "Episode 6 / 10, training time cost: 0.65530\n",
    "Evaluate, loss: 5.96381, accuracy: 0.97430\n",
    "Episode 7 / 10, training time cost: 0.65614\n",
    "Evaluate, loss: 5.94788, accuracy: 0.97850\n",
    "Episode 8 / 10, training time cost: 0.65916\n",
    "Evaluate, loss: 5.93362, accuracy: 0.98070\n",
    "Episode 9 / 10, training time cost: 0.68927\n",
    "Evaluate, loss: 5.92296, accuracy: 0.98340\n",
    "Episode 10 / 10, training time cost: 0.67347\n",
    "Evaluate, loss: 5.91540, accuracy: 0.98610\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose a multi-gpu function to run\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "def main(argv=None):\n",
    "    print('choose a multi-gpu function to run')\n",
    "    # train_on_gpus()\n",
    "    # train_on_cpus_and_gpus()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
