{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存/加载参数 - save/load model of TensorFlow\n",
    "====\n",
    ">MNIST数据集<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-89514d849c4e>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "0.082\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# default graph\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# hyper parameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "\n",
    "# placeholder\n",
    "x = tf.placeholder(tf.float32, [None, input_size], name='placeholder_x')\n",
    "y = tf.placeholder(tf.int64, [None, ], name='placeholder_y')\n",
    "\n",
    "# model\n",
    "# hidden layer\n",
    "fc1 = tf.layers.dense(x, units=128, activation=tf.nn.relu)\n",
    "y_ = tf.layers.dense(fc1, units=num_classes)\n",
    "tf.add_to_collection('logits', y_)\n",
    "\n",
    "# metrics\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_, labels=y)\n",
    "                         , axis=-1)\n",
    "tf.add_to_collection('loss_op', loss_op)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "tf.add_to_collection('train_op', train_op)\n",
    "accuracy_op = tf.reduce_mean(tf.cast(tf.equal(y, tf.argmax(y_, 1)), dtype=tf.float32))\n",
    "tf.add_to_collection('accuracy_op', accuracy_op)\n",
    "\n",
    "# initialize global graph\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# evaluate\n",
    "print(accuracy_op.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "\n",
    "def mkdir(filename):\n",
    "    if os.path.exists(filename):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9561\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    train_op.run({x: batch_xs, y: batch_ys})\n",
    "\n",
    "# evaluate\n",
    "print(accuracy_op.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法一\n",
    "利用`TensorFlow`自带的`save`和`restore`，保存和加载模型。<br>\n",
    "该方式加载模型需要写出模型代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(sess, filename='model1'):\n",
    "    # load\n",
    "    filename = './%s/model.ckpt' % (filename)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, filename)\n",
    "\n",
    "\n",
    "def save(sess, filename='model1'):\n",
    "    # save\n",
    "    mkdir(filename)\n",
    "    filename = './%s/model.ckpt' % (filename)\n",
    "    # 导入网络参数\n",
    "    # Saver参数为空，表示导入全部；若是参数不足，则默认从第0个元素开始倒入，直至参数完成\n",
    "    # saver = tf.train.Saver(tf.all_variables())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, filename)\n",
    "\n",
    "save(sess)\n",
    "# load(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法二\n",
    "利用`Numpy`保存和导入参数<br>\n",
    "该模型的速度非常慢，不建议使用。但是可以将模型的数值保存为numpy格式，便于其他用途"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_np(filename='model2'):\n",
    "    # load\n",
    "    for variables in tf.trainable_variables():\n",
    "        variables.load(value=np.load(os.path.join(filename, variables.name.replace('/', '_') + '.npy')))\n",
    "\n",
    "\n",
    "def save_np(filename='model2'):\n",
    "    # save\n",
    "    mkdir(filename)\n",
    "    for variables in tf.trainable_variables():\n",
    "        np.save(file=os.path.join(filename, variables.name.replace('/', '_') + '.npy'),\n",
    "                arr=variables.eval())\n",
    "\n",
    "save_np()\n",
    "# load_np()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法三\n",
    "利用`TensorFlow`自带的`save`和`restore`，保存和加载图（grarph）。<br>\n",
    "该方式加载模型不需要写出代码，直接使用即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(sess, filename='model3', global_step=None):\n",
    "    # load\n",
    "    saver = tf.train.import_meta_graph('./%s/model-%s.meta' % (filename, global_step))\n",
    "    saver.restore(sess, './%s/model-%s' % (filename, global_step))\n",
    "\n",
    "\n",
    "def save_graph(sess, filename='model3', global_step=None):\n",
    "    # save\n",
    "    mkdir(filename)\n",
    "    saver = tf.train.Saver()\n",
    "    filename = './%s/model' % filename\n",
    "    saver.save(sess, filename, global_step)\n",
    "\n",
    "save_graph(sess, global_step=100)\n",
    "# load_graph(sess, global_step=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法三加载模型\n",
    "在另一脚本中写入一下模型运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model3/model-100\n",
      "before re-training 0.9561\n",
      "after re-training 0.9688\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    load_graph(sess, global_step=100)\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    x = graph.get_operation_by_name('placeholder_x').outputs[0]\n",
    "    y = graph.get_operation_by_name('placeholder_y').outputs[0]\n",
    "\n",
    "    logits = tf.get_collection('logits')[0]\n",
    "    loss_op = tf.get_collection('loss_op')[0]\n",
    "    train_op = tf.get_collection('train_op')[0]\n",
    "    accuracy_op = tf.get_collection('accuracy_op')[0]\n",
    "\n",
    "    feed_dict = {x: mnist.test.images, y: mnist.test.labels}\n",
    "    print('before re-training', accuracy_op.eval(feed_dict=feed_dict))\n",
    "\n",
    "    # continue training\n",
    "    for _ in xrange(100):\n",
    "        batch_images, batch_labels = mnist.test.next_batch(batch_size=100)\n",
    "        feed_dict = {x: batch_images, y: batch_labels}\n",
    "        sess.run(train_op, feed_dict=feed_dict)\n",
    "\n",
    "    feed_dict = {x: mnist.test.images, y: mnist.test.labels}\n",
    "    print('after re-training', accuracy_op.eval(feed_dict=feed_dict))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
