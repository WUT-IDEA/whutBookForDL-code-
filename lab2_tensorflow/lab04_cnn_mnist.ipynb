{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 卷积神经网络(Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six.moves import xrange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "训练集大小: 55000;\n",
      "验证集大小: 5000;\n",
      "测试集大小: 10000.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)\n",
    "print(\n",
    "        '训练集大小: %s;\\n验证集大小: %s;\\n测试集大小: %s.' % \\\n",
    "        (mnist.train.num_examples, mnist.validation.num_examples, mnist.test.num_examples)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算机图形学computer vision\n",
    "计算中，图像可被视为由若干大小相等的举证组成。这些矩阵被称为通道。例如RGB，表示由R红，G绿，B蓝三种颜色组成。二值图一般为单通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# hyper-parameter\n",
    "training_epoch = 100\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "image_size = 28\n",
    "\n",
    "with tf.name_scope('placehold'):\n",
    "    # placehold - define variable\n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, image_size ** 2], name='x')\n",
    "    # -1 for image number; 28,28 for image size; 1 for color channel\n",
    "    input_tensor = tf.reshape(x, shape=(-1, image_size, image_size, 1))\n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, num_classes], name='y')\n",
    "\n",
    "with tf.name_scope('initializer'):\n",
    "    # build an initializer for initializing network\n",
    "    initializer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "\n",
    "\n",
    "def linear(input_data, units=None, activation=tf.nn.relu, name=None):\n",
    "    return tf.layers.dense(inputs=input_data,\n",
    "                           units=units,\n",
    "                           activation=activation,\n",
    "                           kernel_initializer=initializer,\n",
    "                           bias_initializer=initializer,\n",
    "                           name='layer_%s' % (name))\n",
    "\n",
    "\n",
    "def conv2d(input_data, filters=16, kernel_size=(5, 5),\n",
    "           activation=tf.nn.relu, padding='SAME', name=None):\n",
    "    with tf.name_scope('layer_%s' % (name)):\n",
    "        input_data = tf.layers.conv2d(inputs=input_data,\n",
    "                                      filters=filters,\n",
    "                                      kernel_size=kernel_size,\n",
    "                                      strides=(1, 1),\n",
    "                                      activation=activation,\n",
    "                                      padding=padding)\n",
    "        input_data = tf.layers.max_pooling2d(input_data, pool_size=(2, 2), strides=(2, 2), padding=padding)\n",
    "        return input_data\n",
    "\n",
    "\n",
    "# conv1\n",
    "conv1 = conv2d(input_data=input_tensor, filters=32, name='cnn1')\n",
    "conv1 = tf.layers.dropout(inputs=conv1, rate=0.7)\n",
    "# conv2\n",
    "conv2 = conv2d(input_data=conv1, filters=64, name='cnn2')\n",
    "# reshape\n",
    "conv2 = tf.reshape(conv2, [-1, 7 * 7 * 64])\n",
    "# fc1\n",
    "fc1 = linear(input_data=conv2, units=1024, name='fc2')\n",
    "fc1 = tf.layers.dropout(inputs=fc1, rate=0.7)\n",
    "fc2 = linear(input_data=fc1, units=num_classes, name='fc3', activation=tf.nn.softmax)\n",
    "y_ = fc2\n",
    "\n",
    "loss_op = tf.losses.mean_squared_error(labels=y, predictions=y_)\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1)), dtype=tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training & evaluate ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 100, loss: 0.000720134526364, accuracy: 0.995636359128\n",
      "Epoch 20 / 100, loss: 0.000538832720966, accuracy: 0.996927267638\n",
      "Epoch 30 / 100, loss: 0.000711422302202, accuracy: 0.996054540114\n",
      "Epoch 40 / 100, loss: 0.000659064971865, accuracy: 0.996599995115\n",
      "Epoch 50 / 100, loss: 0.000683497654355, accuracy: 0.996436360533\n",
      "Epoch 60 / 100, loss: 0.000473322697859, accuracy: 0.997599994486\n",
      "Epoch 70 / 100, loss: 0.000795798837745, accuracy: 0.995945450393\n",
      "Epoch 80 / 100, loss: 0.000785153461347, accuracy: 0.996054541198\n",
      "Epoch 90 / 100, loss: 0.00375222392155, accuracy: 0.981181825616\n",
      "Epoch 100 / 100, loss: 0.000678467370861, accuracy: 0.996581812989\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_episode = len(mnist.train.images) // batch_size\n",
    "for i in xrange(1, 1 + training_epoch):\n",
    "    for _ in xrange(batch_episode):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        train_op.run(feed_dict={x: batch_x, y: batch_y})\n",
    "    if i % 10 == 0:\n",
    "        # 避免显存不足\n",
    "        acc = 0.0\n",
    "        for _ in xrange(batch_episode):\n",
    "            batch_x, batch_y = mnist.test.next_batch(batch_size)\n",
    "            batch_acc = session.run([accuracy], feed_dict={x: batch_x, y: batch_y})\n",
    "            acc += batch_acc\n",
    "        print('Epoch %s / %s, accuracy: %s' % (i, training_epoch, acc / batch_episode))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN的优点：<br>\n",
    "1.CNN考虑的是区域的特征，对于图像有着其他网络能以比拟的性能（可以认为：凡是涉及到图像的模型，都能加上CNN）。矩阵也可以被视为是图像。<br>\n",
    "2.网络参数少。能够加速网络的训练。<br>\n",
    "\n",
    "缺点：<br>\n",
    "1.若是CNN层数多，网络的学习速度也变慢。<br>\n",
    "\n",
    "推荐：\n",
    "1.画风迁移Neural Transfer:<br>\n",
    "http://pytorch.org/tutorials/advanced/neural_style_tutorial.html<br>\n",
    "2.经典的CNN网络（关注网页中的Convolutional nets模块）：<br>\n",
    "http://yann.lecun.com/exdb/mnist/<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐资料：<br>\n",
    "[Stanford UFLDL课程，Feature extraction using convolution](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)<br>\n",
    "[Stanford UFLDL课程，Pooling](http://deeplearning.stanford.edu/wiki/index.php/Pooling)<br>\n",
    "[TensorFlow利用CNN实现MNIST识别](https://www.tensorflow.org/tutorials/layers)<br>\n",
    "[TensorFlow利用CNN实现CIFAR-10识别](https://www.tensorflow.org/tutorials/deep_cnn)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
