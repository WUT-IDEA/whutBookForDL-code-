{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 全相连网络(Fully Connected Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入MNIST数据集<br>\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist/)(读作minist)，是由LeCunn等三位大佬在98年贡献的手写数字数据集。<br>\n",
    "每张图片为28*28像素的二值图，算得上是深度学习的入门资料。地位如同helloworld程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6e8568aa84b3>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "训练集大小: 55000;\n",
      "验证集大小: 5000;\n",
      "测试集大小: 10000.\n",
      "输入的大小：784\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)\n",
    "print(\n",
    "        '训练集大小: %s;\\n验证集大小: %s;\\n测试集大小: %s.' % \\\n",
    "        (mnist.train.num_examples, mnist.validation.num_examples, mnist.test.num_examples)\n",
    ")\n",
    "image_size = mnist.train.images[0].shape[0]\n",
    "print('输入的大小：%s' % (image_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcEAAAAAAH9lwLAAAAeElEQVR4nO2SOw7AMAhDSZT7XzndWgE2OEOlDvUY+RHzMfv1IQ38vPdtII4RjcSW8KlgyDE7hKGrilOlIa0j1BeWo0a14BPVh17Zmk1IAOwhAGpQAiM2iruCPfrB43UkkB11+aMKmR3sMRZ963LYfw3IMSnqycgEXYkPJCx6Icq0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=I size=28x28 at 0x7F4C615CD710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "Image.fromarray(np.reshape(a=mnist.train.images[0], newshape=(28, 28)), 'I')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化实现(regularization)\n",
    "\n",
    "### i).自定义网络参数矩阵实现<br>\n",
    "``\n",
    "weight_a = tf.Variable(tf.random_normal(shape=[original, target], mean=.0, stddev=.1))\n",
    "weight_b = tf.Variable(tf.zeros(shape=[target]))\n",
    "tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(1e-4)(weight_a))\n",
    "tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(1e-4)(weight_b))\n",
    "tf.add_to_collection('losses', loss_function)\n",
    "loss_op = tf.add_n(tf.get_collection('losses'))\n",
    "``<br>\n",
    "\n",
    "### ii).TensorFlow layer函数实现<br>\n",
    "``\n",
    "tf.layers.dense(kernel_regularizer=1e-4, bias_regularizer=1e-4)\n",
    "tf.add_to_collection(name=tf.GraphKeys.REGULARIZATION_LOSSES, value=loss_function))\n",
    "loss_op = tf.reduce_mean(tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)))\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch norm（一维）\n",
    "\n",
    "### 方式1\n",
    "``\n",
    "mean, var = tf.nn.moments(input_tensor, axes=[0])\n",
    "shift = tf.Variable(tf.zeros(input_tensor.get_shape()[-1]))\n",
    "scale = tf.Variable(tf.zeros(input_tensor.get_shape()[-1]))\n",
    "variance_epsilon = 1e-4\n",
    "output = tf.nn.batch_normalization(input_data, mean, var, shift, scale, epsilon)\n",
    "``\n",
    "\n",
    "### 方式2\n",
    "``\n",
    "output = (input_tensor - mean) / tf.sqrt(var + variance_epsilon)\n",
    "output = output * scale + offset\n",
    "``\n",
    "\n",
    "### 方式3\n",
    "``\n",
    "def mean_var_with_update():\n",
    "    ema_apply_op = ema.apply([mean, var])\n",
    "    with tf.control_dependencies([ema_apply_op]):\n",
    "        return tf.identity(mean), tf.identity(var)\n",
    "``<br>\n",
    "``\n",
    "ema = tf.train.ExponentialMovingAverage(decay=0.9)\n",
    "mean, var = mean_var_with_update()\n",
    "output = tf.nn.batch_normalization(input_tensor, mean, var, offset, scale, variance_epsilon)\n",
    "``\n",
    "\n",
    "## batch norm（二维）\n",
    "``\n",
    "mean, var = tf.nn.moments(input_tensor, [0, 1, 2], keep_dims=True)\n",
    "shift = tf.Variable(tf.zeros(input_tensor.get_shape()[-1]))\n",
    "scale = tf.Variable(tf.zeros(input_tensor.get_shape()[-1]))\n",
    "epsilon = 1e-3\n",
    "output = tf.nn.batch_normalization(input_data, mean, var, shift, scale, epsilon)\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 超参数(hyper-parameter)是指构成网络的参数，迭代次数/batch大小也可以作为超参数的一部分\n",
    "training_epoch = 100\n",
    "num_class = 10\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.name_scope('placehold'):\n",
    "        # placehold - define variable\n",
    "        x = tf.placeholder(dtype=tf.float32, shape=[None, image_size], name='x')\n",
    "        y = tf.placeholder(dtype=tf.float32, shape=[None, num_class], name='y')\n",
    "\n",
    "\n",
    "    def linear(input_data, name=None, target=None, activation=tf.nn.relu, norm=False):\n",
    "        original = int(list(input_data.shape)[-1])\n",
    "        with tf.name_scope('layer_%s' % (name)):\n",
    "            # define two variable for y=a*x+b\n",
    "            weight_a = tf.Variable(tf.random_normal(shape=[original, target], mean=.0, stddev=.1),\n",
    "                                   name='layer_%s_a' % (name))\n",
    "            weight_b = tf.Variable(tf.zeros(shape=[target]), name='layer_%s_b' % (name))\n",
    "            \n",
    "            output = tf.matmul(input_data, weight_a) + weight_b\n",
    "            # batch normalize\n",
    "            if norm:\n",
    "                mean, var = tf.nn.moments(output, axes=[0])\n",
    "                offset = tf.Variable(tf.ones([target]))\n",
    "                scale = tf.Variable(tf.ones([target]))\n",
    "                variance_epsilon = 1e-4\n",
    "                output = tf.nn.batch_normalization(output, mean, var, offset, scale, variance_epsilon)\n",
    "                \n",
    "        return activation(output)\n",
    "\n",
    "\n",
    "    # MLP\n",
    "    fc1 = linear(input_data=x, name='1', target=256)\n",
    "    # dropout是神经网络中重要的提示网络性能的手段。它不是网络。\n",
    "    # dropout可以放置norm过拟合，提升网络准确率，得到数据特征等作用。\n",
    "    # 类似的还有batchnorm等，都对网络性能的提升有着关键性的作用\n",
    "    fc1 = tf.layers.dropout(inputs=fc1, rate=0.7)\n",
    "    fc2 = linear(input_data=fc1, name='2', target=64)\n",
    "    fc3 = linear(input_data=fc2, name='3', target=num_class, activation=tf.nn.softmax)\n",
    "    y_ = fc3\n",
    "\n",
    "    with tf.name_scope('loss_op'):\n",
    "        tf.add_to_collection('losses', tf.losses.mean_squared_error(y, y_))\n",
    "        loss_op = tf.add_n(tf.get_collection('losses'))\n",
    "    with tf.name_scope('train_op'):\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_op)\n",
    "    with tf.name_scope('accuracy_op'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1)), tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch不宜太大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 100, loss: 0.007501135, accuracy: 0.9764\n",
      "Epoch 20 / 100, loss: 0.0076487865, accuracy: 0.9757\n",
      "Epoch 30 / 100, loss: 0.00798492, accuracy: 0.9763\n",
      "Epoch 40 / 100, loss: 0.006740521, accuracy: 0.9797\n",
      "Epoch 50 / 100, loss: 0.0077452576, accuracy: 0.9778\n",
      "Epoch 60 / 100, loss: 0.0072739497, accuracy: 0.9789\n",
      "Epoch 70 / 100, loss: 0.007299751, accuracy: 0.9794\n",
      "Epoch 80 / 100, loss: 0.0078655705, accuracy: 0.9785\n",
      "Epoch 90 / 100, loss: 0.0074387654, accuracy: 0.9799\n",
      "Epoch 100 / 100, loss: 0.006868942, accuracy: 0.9812\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    batch_episode = len(mnist.train.images) // batch_size\n",
    "    for i in xrange(1, 1 + training_epoch):\n",
    "        for _ in xrange(batch_episode):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            feed = {x: batch_x, y: batch_y}\n",
    "            _, batch_cost, batch_acc = session.run([train_op, loss_op, accuracy], feed_dict=feed)\n",
    "        if i % 10 == 0:\n",
    "            loss_val, acc_val = session.run([loss_op, accuracy], feed_dict={\n",
    "                x: mnist.test.images,\n",
    "                y: mnist.test.labels\n",
    "            })\n",
    "            print('Epoch %s / %s, loss: %s, accuracy: %s' % (i, training_epoch, loss_val, acc_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检验\n",
    "estimaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcEAAAAAAH9lwLAAAAa0lEQVR4nO2UQQ7AIAgEtf//s15ps8vQGpMe5GZkHEjA1k78KHo8jBEu+jO1CMrkkH3VCgMjuaMROrk/87JUhS30iKD27TM6X9GopigFs0lKQF9mCtLcYo9uSwxIPjT6rZQg+3ZNDn0fn2IC6zAYJYGcViEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=I size=28x28 at 0x7F4C56C427F0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在深度学习中实际值/真实值叫做ground truth\n",
    "Image.fromarray(np.reshape(a=mnist.test.images[0], newshape=(28, 28)), 'I')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted image is 4\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    predict = session.run([y_], feed_dict={\n",
    "        x: mnist.test.images[0][None, ...],\n",
    "        y: mnist.test.labels[0][None, ...]\n",
    "    })\n",
    "    # prediction\n",
    "    print('predicted image is %s' % (np.argmax(a=predict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推荐资料：<br>\n",
    "[Stanford UFLDL课程，神经网络](http://deeplearning.stanford.edu/wiki/index.php/Neural_Networks)<br>\n",
    "[Stanford UFLDL课程，backprogation算法](http://deeplearning.stanford.edu/wiki/index.php/Backpropagation_Algorithm)<br>\n",
    "[Stanford UFLDL课程，backprogation算法](http://deeplearning.stanford.edu/wiki/index.php/Backpropagation_Algorithm)<br>\n",
    "[Stanford UFLDL课程，梯度检验与高级优化](http://deeplearning.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization)<br>\n",
    "[Micheal Nielsen, *Neural Networks and Deep Learning*](http://neuralnetworksanddeeplearning.com/index.html)<br>\n",
    "[sklearn库，神经网络](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)<br>\n",
    "[TensorFLow全相连网络实现MNIST识别（教程代码的版本太低）](http://www.tensorfly.cn/tfdoc/tutorials/mnist_beginners.html)<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
